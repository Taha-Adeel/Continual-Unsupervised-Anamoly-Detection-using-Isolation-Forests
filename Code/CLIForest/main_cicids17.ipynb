{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.iforest import IsolationForest\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, f1_score, average_precision_score\n",
    "from util.utils import find_TPR_threshold\n",
    "from sklearn.ensemble import IsolationForest as skIsolationForest\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from dataset.cicids17 import CICIDS17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "n_estimators = 100\n",
    "max_samples = 50000\n",
    "test_size = 0.7 # Unused currently\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "dataset = CICIDS17()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Isolation Forest\n",
    "clf_forests = []\n",
    "for X, y, _, filename in dataset.datasets:\n",
    "    print(f'Training Isolation Forest on {filename}')\n",
    "    iforest = IsolationForest(sample_size=max_samples, n_trees=n_estimators)\n",
    "    start_time = time.time()\n",
    "    iforest.fit(X, improved=False)\n",
    "    clf_forests.append((iforest, filename))\n",
    "    end_time = time.time()\n",
    "    print(f'{max_samples=}, {n_estimators=}, training time: {end_time - start_time:.3f}s\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (iforest, filename), (X, y, _, _) in zip(clf_forests, dataset.datasets):\n",
    "    print(f'Predicting on {filename}')\n",
    "    print(f'Dataset shape: {X.shape}')\n",
    "    print(f'Benign samples: {y.value_counts()[0]}')\n",
    "    print(f'Anomalies in dataset: {y.value_counts().get(1, 0)}')\n",
    "    print(f'Contamination rate: {y.value_counts().get(1, 0) / y.count() * 100:.4f} %\\n')\n",
    "    \n",
    "    # Predict\n",
    "    start_time = time.time()\n",
    "    scores = iforest.anomaly_score(X)\n",
    "    threshold, FPR = find_TPR_threshold(y, scores, 0.5)\n",
    "    y_pred = iforest.predict_from_anomaly_scores(scores, threshold)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    # Metrics\n",
    "    plt.hist(scores, bins=30, label=f'{filename}')\n",
    "    print(f'Prediction time: {end_time - start_time:.3f}s')\n",
    "    print('Predictions: ')\n",
    "    print(pd.Series(y_pred).value_counts())\n",
    "    print(confusion_matrix(y, y_pred))\n",
    "    print(classification_report(y, y_pred))\n",
    "    print(f'ROC AUC: {roc_auc_score(y, y_pred):.4f}')\n",
    "    print(f'PR AUC: {average_precision_score(y, y_pred):.4f}')\n",
    "    print(f'F1 Score: {f1_score(y, y_pred):.4f}')\n",
    "    print(f'Threshold: {threshold:.4f}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train using sklearn\n",
    "sk_iforests = []\n",
    "for (X, y, _, filename) in dataset.datasets:\n",
    "    print(f'Training Isolation Forest on {filename}')\n",
    "    iforest = skIsolationForest(n_estimators=n_estimators, max_samples=max_samples, contamination='auto', n_jobs=-1, random_state=seed)\n",
    "    start_time = time.time()\n",
    "    iforest.fit(X)\n",
    "    sk_iforests.append((iforest, filename))\n",
    "    end_time = time.time()\n",
    "    print(f'{n_estimators=}, {max_samples=}, training time: {end_time - start_time:.3f}s\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict using sklearn\n",
    "for (iforest, filename), (X, y, _, _) in zip(sk_iforests, dataset.datasets):\n",
    "    print(f'Predicting on {filename}')\n",
    "    print(f'Dataset shape: {X.shape}')\n",
    "    print(f'Benign samples: {y.value_counts()[0]}')\n",
    "    print(f'Anomalies in dataset: {y.value_counts().get(1, 0)}')\n",
    "    print(f'Contamination rate: {y.value_counts().get(1, 0) / y.count() * 100:.4f} %\\n')\n",
    "    \n",
    "    # Predict\n",
    "    start_time = time.time()\n",
    "    y_pred = [1 if x == -1 else 0 for x in iforest.predict(X)]\n",
    "    end_time = time.time()\n",
    "    \n",
    "    # Metrics\n",
    "    print(f'Prediction time: {end_time - start_time:.3f}s')\n",
    "    print('Predictions: ')\n",
    "    print(pd.Series(y_pred).value_counts())\n",
    "    print(confusion_matrix(y, y_pred))\n",
    "    print(classification_report(y, y_pred))\n",
    "    print(f'ROC AUC: {roc_auc_score(y, y_pred):.4f}')\n",
    "    print(f'PR AUC: {average_precision_score(y, y_pred):.4f}')\n",
    "    print(f'F1 Score: {f1_score(y, y_pred):.4f}')\n",
    "    print(f'Threshold: {threshold:.4f}\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nids",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
